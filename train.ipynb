{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/georg/virtenvs/tensorflow36/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:430: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n",
      "WARNING:tensorflow:From /home/georg/virtenvs/tensorflow36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from fast5_input import fast5batches\n",
    "from model import x, sequence_length, num_features, batch_size, segment_length, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('labels'):\n",
    "    indices = tf.placeholder(tf.int64, name='indices')\n",
    "    y = tf.placeholder(tf.int32, name='values')\n",
    "    dense_shape = (batch_size, segment_length)\n",
    "\n",
    "    labels = tf.SparseTensor(indices = indices, \n",
    "                             values = y, \n",
    "                             dense_shape = dense_shape\n",
    "                            )\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.ctc_loss(labels = labels, \n",
    "                       inputs = logits, \n",
    "                       sequence_length = sequence_length, \n",
    "                       time_major=False\n",
    "                      )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.get_variable('global_step', trainable=False, shape=(),\n",
    "                              dtype=tf.int32,\n",
    "                              initializer=tf.zeros_initializer())\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "step = optimizer.minimize(loss, global_step = global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('error'):\n",
    "    logits_transposed = tf.transpose(logits, perm=[1, 0, 2])\n",
    "    decoded, neg_sum_logits = tf.nn.ctc_beam_search_decoder(\n",
    "                logits_transposed,\n",
    "                sequence_length,\n",
    "                merge_repeated=False,\n",
    "                top_paths=1,\n",
    "                beam_width=30)\n",
    "    first_path = decoded[0]\n",
    "    edit_d = tf.edit_distance(tf.to_int32(first_path), labels, normalize=True)\n",
    "    error = tf.reduce_mean(edit_d, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'log/save'\n",
    "\n",
    "summary_train = tf.summary.merge([tf.summary.scalar('learning_rate', learning_rate), \n",
    "                                  tf.summary.scalar('loss', loss)])\n",
    "summary_test = tf.summary.merge([tf.summary.scalar('Error_rate', error)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checking files: 100%|██████████| 34383/34383 [00:17<00:00, 1946.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29849 files have labels, 23880 for training and 5969 for testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "f5b = fast5batches(batch_size=batch_size, \n",
    "                   segment_length=segment_length, \n",
    "                   fast5dir='../chiron-otrain/pass', \n",
    "                   training=True, \n",
    "                   test_ratio=.2,\n",
    "                   overlap=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:15,  7.06it/s]\n",
      "200it [00:16,  6.27it/s]\n"
     ]
    }
   ],
   "source": [
    "f5b.next_batch(test=False, fill=True)\n",
    "f5b.next_batch(test=True, fill=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "it: 1880, err: 22.23%,  loss: 34.34: 2024it [1:38:06,  2.91s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-98d0a2a06a96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mln\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf5b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             feed_dict = {x: X, \n\u001b[1;32m     26\u001b[0m                          \u001b[0msequence_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mln\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fast5basecaller/fast5_input.py\u001b[0m in \u001b[0;36mnext_batch\u001b[0;34m(self, test, fill)\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast5_to_valnlab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegment_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverlap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0mnew_raw_signals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_sequence_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fast5basecaller/fast5_input.py\u001b[0m in \u001b[0;36mfast5_to_valnlab\u001b[0;34m(file_path, segment_length, training, overlap)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0msequence_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mdata_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtenvs/tensorflow36/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   1872\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1874\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1875\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m             \u001b[0msum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "name = 'timeonlylast_exp-2_1'\n",
    "summary_path = 'logs/summary/' + name\n",
    "lr_val = 10**-2\n",
    "err_val_low = None\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    summary_writer = tf.summary.FileWriter(summary_path, sess.graph)\n",
    "    try:\n",
    "        saver.restore(sess, './logs/save/{}.ckpt'.format(name))\n",
    "        \n",
    "        X, ln, Y, fi = f5b.next_batch(test=True)\n",
    "        feed_dict = {x: X, \n",
    "                     sequence_length: ln, \n",
    "                     indices: Y.indices, \n",
    "                     y: Y.values,}\n",
    "        err_val_low, loss_val, gs_val = sess.run([error, loss, global_step], feed_dict = feed_dict)\n",
    "        desc = 'it: {}, err: {.3},  loss: {.2}'.format(gs_val, err_val, loss_val)\n",
    "    except ValueError:\n",
    "        print('initialize variables')\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    with tqdm() as bar:\n",
    "        while True:\n",
    "            X, ln, Y, fi = f5b.next_batch(test=False)\n",
    "            feed_dict = {x: X, \n",
    "                         sequence_length: ln, \n",
    "                         indices: Y.indices, \n",
    "                         y: Y.values,\n",
    "                         learning_rate: lr_val}\n",
    "            summary, _, gs_val, loss_val = sess.run([summary_train, step, global_step, loss], feed_dict = feed_dict)\n",
    "            summary_writer.add_summary(summary, global_step=gs_val)\n",
    "            summary_writer.flush()\n",
    "            bar.n = gs_val\n",
    "            bar.refresh()\n",
    "            if gs_val%10==0:\n",
    "                X, ln, Y, fi = f5b.next_batch(test=True)\n",
    "                feed_dict = {x: X, \n",
    "                             sequence_length: ln, \n",
    "                             indices: Y.indices, \n",
    "                             y: Y.values,}\n",
    "                summary, err_val, gs_val = sess.run([summary_test, error, global_step], feed_dict = feed_dict)\n",
    "                summary_writer.add_summary(summary, global_step=gs_val)\n",
    "                summary_writer.flush()\n",
    "                if err_val_low is None or err_val<err_val_low:\n",
    "                    err_val_low = err_val\n",
    "                    bar.desc = '{:.2%} lowest error rate at {}, training'.format(err_val, gs_val)\n",
    "                    saver.save(sess, './logs/save/{}.ckpt'.format(name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prona",
   "language": "python",
   "name": "prona"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
